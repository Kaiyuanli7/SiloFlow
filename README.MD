# ğŸ›¢ï¸ SiloFlow â€“ Grain-Temperature Forecasting Pipeline

SiloFlow is an end-to-end toolkit that ingests raw sensor CSVs from grain warehouses, cleans & enriches the data, trains a machine-learning model, and visualises both historical and forecast temperatures through a Streamlit dashboard.

The project started as *GranaryPredict* and was renamed in May-2025 â€“ imports remain backward-compatible via the `siloflow` â†”ï¸ `granarypredict` alias.

---

## Key Capabilities

1. **Data ingestion** â€“ parse the StorePoint CSV export or any file mapped to the canonical schema.
2. **Cleaning & imputation** â€“ handle duplicates, obvious sentinels (â€999/â€œNAâ€), forward/back-fill categorical gaps, statistical fill for numerics.
3. **Feature engineering**
   â€¢ cyclic calendar features (month/hour sin & cos)  
   â€¢ 1-, 7-, 30-day sensor lag + âˆ†T  
   â€¢ rolling mean/std windows  
   â€¢ auto-label-encoding for categoricals
4. **ğŸš€ PERFORMANCE OPTIMIZATIONS (NEW)**
   â€¢ **Anchor-day early stopping**: 10x faster with interval checking (every 10 iterations)
   â€¢ **Fast Optuna mode**: 2-fold CV, lower tree limits, aggressive early stopping
   â€¢ **Vectorized computations**: Batch operations for 7-day consecutive accuracy
   â€¢ **Minimal memory usage**: Essential columns only in optimization loops
5. **Model zoo** â€“ Random Forest, HistGradientBoost, tuned LightGBM (+ optional Multi-Output wrapper).  
   Hyper-parameters can be overridden at run-time or via `granarypredict.model.train_*` helpers.
6. **Evaluation suite** â€“ per-horizon MAE/RMSE, overall confidence & accuracy, plus a brand-new *Extremes* tab that spot-lights biggest over/under predictions and average daily error.
7. **Forecasting** â€“ one-click generation of t+1â€¦t+3-day predictions; optionally *future-safe* (excludes environment-only columns).
8. **Production REST API** â€“ `/ingest` CSV-upload endpoint and `/forecast` JSON endpoint built with FastAPI & APScheduler; supports automatic weekly retraining and multi-horizon output.
9. **Cascaded selectors** â€“ Warehouse â†’ Silo filters propagate across all plots & tables.
10. **Synthetic data generator** â€“ create reproducible demo datasets for quick experimentation.

---

## Directory Overview
```
â”œâ”€ app/                  # Streamlit dashboard (run this!)
â”‚   â”œâ”€ Dashboard.py
â”‚   â””â”€ debug_future.py   # optional CLI reproduction of the dashboard logic
â”‚
â”œâ”€ data/
â”‚   â”œâ”€ preloaded/        # sample CSVs shipped with the repo
â”‚   â”œâ”€ raw/              # untouched dumps (and by_silo/ organiser output)
â”‚   â””â”€ processed/        # cleaned feature tables (optional)
â”‚
â”œâ”€ granarypredict/       # Core Python package
â”‚   â”œâ”€ ingestion.py      # file / API loaders + schema mapping
â”‚   â”œâ”€ cleaning.py       # data cleansing utilities
â”‚   â”œâ”€ features.py       # feature engineering helpers
â”‚   â”œâ”€ model.py          # training / persistence / inference
â”‚   â”œâ”€ evaluate.py       # cross-validation helpers
â”‚   â””â”€ ...
â”‚
â”œâ”€ service/              # FastAPI micro-service (ingest + forecast endpoints)
â”œâ”€ models/               # saved .joblib models (auto-created)
â”œâ”€ scripts/              # CLI helpers (trainer, synthetic data) 
â””â”€ README.md             # â† you are here
```

---

## Quick-Start (Windows / macOS / Linux)

# 1. Clone & enter repo
cmd: git clone -b v1 https://github.com/kaiyuanli7/siloflow.git
cmd: cd siloflow

# 2. Create & activate a Python 3.11 virtual environment
cmd: python -m venv .venv
cmd: .venv\Scripts\activate.bat

# 3. Install requirements (use a mirror if behind a firewall)
cmd: pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
cmd: python -m pip install --upgrade pip
cmd: pip install -r requirements.txt

# 5. Launch dashboard
cmd: streamlit run app/Dashboard.py

Open http://localhost:8501 and explore:
1. ğŸ“‚ **Data** â€“ upload a CSV or pick a bundled sample.
2. ğŸ—ï¸ **Train / Retrain** â€“ choose algorithm, iterations, and **split mode**:
   â€¢ *Percentage* (e.g. 80 / 20)  
   â€¢ *Last 30 days* (train on history, validate on the most recent month)
3. ğŸ” **Evaluate Model** â€“ get per-horizon metrics, 3-D grid, time-series, and the **Extremes** analysis:
   â€¢ average daily |error|  
   â€¢ worst over-prediction row per day  
   â€¢ worst under-prediction row per day  
   â€¢ plots of the above
4. ğŸ”® **Forecast** â€“ extend predictions into the future and compare max/min hot-spots.

---

## Canonical CSV Schema
Column | Type | Notes
-------|------|------
`detection_time` | datetime | timestamp of sensor reading
`granary_id` | str | warehouse name (ä¸­æ–‡ allowed)
`heap_id` | str | silo / heap identifier
`grid_x, grid_y, grid_z` | int | 3-D probe location
`temperature_grain` | float | Â°C at probe
`temperature_inside/outside` | float | env temps (optional for future-safe models)
`humidity_warehouse/outside` | float | %RH (optional)
`avg_grain_temp` | float | daily average (optional)

The `granarypredict.ingestion.standardize_granary_csv()` helper converts StorePoint/Result-147 headers automatically.

---

## Command-Line Utilities

â€¢ **Synthetic data**  
```bash
python scripts/generate_fake_sensor_data.py --days 30 --grid 4 5 3 \
       --output data/raw/synthetic_sensor.csv
```

â€¢ **Global model trainer** (multi-file)  
```bash
python scripts/train_global_model.py data/raw/*.csv --algo lgbm --n-estimators 1200 --future-safe
```

---

## Extending / Customising

| What you want | Where to look |
|---------------|--------------|
Tweak hyper-parameters | `granarypredict/model.py` / dashboard training sidebar |
Add new features | `granarypredict/features.py` |
Change alert thresholds | `granarypredict/config.py` |
Integrate REST weather API | `granarypredict/ingestion.py` |

---

## Contributing
Pull requests are welcome!  Please run `flake8` & `black`, and test the dashboard locally before submitting.  For significant changes, update this README accordingly.

---

Â© 2025 Kaiyuan Li â€“ MIT License

---

## REST API Endpoints

Once the service is running (see step 6 above) interactive Swagger docs are available at `/docs`.  The primary endpoints are:

| Method | Path | Purpose |
|--------|------|---------|
| POST   | `/ingest`   | Append a daily CSV dump to the historical store. |
| POST   | `/forecast` | Return 1-, 2-, 3-day grain-temperature predictions for the given granary as JSON (and persists a CSV under `data/forecast/`). |
| GET    | `/healthz`  | Simple liveness probe used by Docker/K8s. |

The service schedules a weekly retraining job (cron style) which can be adjusted in `service/schedule_config.json`.

---

